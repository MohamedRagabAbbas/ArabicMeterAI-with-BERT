{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length=512\n",
    "num_meter_classes = 23\n",
    "batch_size = 1\n",
    "learning_rate = 3e-4\n",
    "num_epochs = 10\n",
    "top = 10000\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at asafaya/bert-base-arabic and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('asafaya/bert-base-arabic')\n",
    "model = BertForSequenceClassification.from_pretrained('asafaya/bert-base-arabic', num_labels=num_meter_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>الشطر</th>\n",
       "      <th>البحر</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>خَليلَيَّ لا تَستَعجِلا أَن تَزَوَّدا</td>\n",
       "      <td>الطويل</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>فَما لَبَثٌ يَوماً بِسابِقٍ مَغنَمٍ</td>\n",
       "      <td>الطويل</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>وَإِن تُنظِراني اليَومَ أَقضِ لُبانَةً</td>\n",
       "      <td>الطويل</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>لَعَمرُكَ ما نَفسٌ بِجِدٍ رَشيدَةٍ</td>\n",
       "      <td>الطويل</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>وَإِن ظَهَرَت مِنهُ قَوارِصُ جَمَّةٌ</td>\n",
       "      <td>الطويل</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    الشطر   البحر\n",
       "0   خَليلَيَّ لا تَستَعجِلا أَن تَزَوَّدا  الطويل\n",
       "1     فَما لَبَثٌ يَوماً بِسابِقٍ مَغنَمٍ  الطويل\n",
       "2  وَإِن تُنظِراني اليَومَ أَقضِ لُبانَةً  الطويل\n",
       "3      لَعَمرُكَ ما نَفسٌ بِجِدٍ رَشيدَةٍ  الطويل\n",
       "4    وَإِن ظَهَرَت مِنهُ قَوارِصُ جَمَّةٌ  الطويل"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meters = pd.read_csv('meter.csv')\n",
    "#meters = meters[:top]\n",
    "meters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "البحر\n",
      "الطويل      516720\n",
      "الكامل      440698\n",
      "البسيط      290574\n",
      "الخفيف      191568\n",
      "الوافر      170820\n",
      "الرجز       115762\n",
      "الرمل        85472\n",
      "المتقارب     84778\n",
      "السريع       76166\n",
      "Name: count, dtype: int64\n",
      "البحر\n",
      "الطويل      516720\n",
      "الكامل      440698\n",
      "البسيط      290574\n",
      "الخفيف      191568\n",
      "الوافر      170820\n",
      "الرجز       115762\n",
      "الرمل        85472\n",
      "المتقارب     84778\n",
      "السريع       76166\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## print how many each class appears in the dataset\n",
    "print(meters['البحر'].value_counts())\n",
    "## drop class which has less than 70000 instances\n",
    "meters = meters[meters['البحر'] != 'المنسرح']\n",
    "meters = meters[meters['البحر'] != 'موشح']\n",
    "meters = meters[meters['البحر'] != 'المجتث']\n",
    "meters = meters[meters['البحر'] != 'الهزج']\n",
    "meters = meters[meters['البحر'] != 'المديد']\n",
    "meters = meters[meters['البحر'] != 'المتدارك']\n",
    "meters = meters[meters['البحر'] != 'الدوبيت']\n",
    "meters = meters[meters['البحر'] != 'المواليا']\n",
    "meters = meters[meters['البحر'] != 'السلسلة']\n",
    "meters = meters[meters['البحر'] != 'المقتضب']\n",
    "meters = meters[meters['البحر'] != 'عامي']\n",
    "meters = meters[meters['البحر'] != 'المضارع']\n",
    "meters = meters[meters['البحر'] != 'شعر التفعيلة']\n",
    "meters = meters[meters['البحر'] != 'شعر حر']\n",
    "print(meters['البحر'].value_counts())\n",
    "## save the new dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "meters.to_csv('meter_filtered.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArabicPoetryDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.encodings = tokenizer(texts, truncation=True, padding=True)\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'الطويل': 0,\n",
       " 'المنسرح': 1,\n",
       " 'المتقارب': 2,\n",
       " 'الخفيف': 3,\n",
       " 'الكامل': 4,\n",
       " 'السريع': 5,\n",
       " 'الوافر': 6,\n",
       " 'البسيط': 7,\n",
       " 'الرجز': 8,\n",
       " 'الرمل': 9,\n",
       " 'المجتث': 10,\n",
       " 'المديد': 11}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meters['البحر'].unique()\n",
    "label_dict = {label: i for i, label in enumerate(meters['البحر'].unique())}\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = meters['الشطر']\n",
    "label = meters['البحر']\n",
    "label = label.apply(lambda x: label_dict[x])\n",
    "texts = text.to_list()\n",
    "labels = label.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Assuming 'labels' is a list or array of your labels\n",
    "label_counts = np.unique(labels, return_counts=True)\n",
    "print(dict(zip(label_counts[0], label_counts[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "dataset = ArabicPoetryDataset(texts, labels)\n",
    "dataloader = DataLoader(dataset, batch_size = batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 10000\n",
      "Number of batches: 10000\n"
     ]
    }
   ],
   "source": [
    "print('Dataset size:', len(dataset))\n",
    "print('Number of batches:', len(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[215], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m losses \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((losses, loss\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m)))\n\u001b[0;32m     18\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\AUC\\anaconda3\\Lib\\site-packages\\torch\\optim\\optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m             )\n\u001b[1;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\AUC\\anaconda3\\Lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Users\\AUC\\anaconda3\\Lib\\site-packages\\torch\\optim\\adamw.py:188\u001b[0m, in \u001b[0;36mAdamW.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    175\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    177\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    178\u001b[0m         group,\n\u001b[0;32m    179\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    185\u001b[0m         state_steps,\n\u001b[0;32m    186\u001b[0m     )\n\u001b[1;32m--> 188\u001b[0m     adamw(\n\u001b[0;32m    189\u001b[0m         params_with_grad,\n\u001b[0;32m    190\u001b[0m         grads,\n\u001b[0;32m    191\u001b[0m         exp_avgs,\n\u001b[0;32m    192\u001b[0m         exp_avg_sqs,\n\u001b[0;32m    193\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    194\u001b[0m         state_steps,\n\u001b[0;32m    195\u001b[0m         amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[0;32m    196\u001b[0m         beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[0;32m    197\u001b[0m         beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[0;32m    198\u001b[0m         lr\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    199\u001b[0m         weight_decay\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    200\u001b[0m         eps\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    201\u001b[0m         maximize\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    202\u001b[0m         foreach\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforeach\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    203\u001b[0m         capturable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    204\u001b[0m         differentiable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    205\u001b[0m         fused\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfused\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    206\u001b[0m         grad_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    207\u001b[0m         found_inf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    208\u001b[0m         has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[0;32m    209\u001b[0m     )\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\AUC\\anaconda3\\Lib\\site-packages\\torch\\optim\\adamw.py:340\u001b[0m, in \u001b[0;36madamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    338\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[1;32m--> 340\u001b[0m func(\n\u001b[0;32m    341\u001b[0m     params,\n\u001b[0;32m    342\u001b[0m     grads,\n\u001b[0;32m    343\u001b[0m     exp_avgs,\n\u001b[0;32m    344\u001b[0m     exp_avg_sqs,\n\u001b[0;32m    345\u001b[0m     max_exp_avg_sqs,\n\u001b[0;32m    346\u001b[0m     state_steps,\n\u001b[0;32m    347\u001b[0m     amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[0;32m    348\u001b[0m     beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[0;32m    349\u001b[0m     beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[0;32m    350\u001b[0m     lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[0;32m    351\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[0;32m    352\u001b[0m     eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[0;32m    353\u001b[0m     maximize\u001b[38;5;241m=\u001b[39mmaximize,\n\u001b[0;32m    354\u001b[0m     capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[0;32m    355\u001b[0m     differentiable\u001b[38;5;241m=\u001b[39mdifferentiable,\n\u001b[0;32m    356\u001b[0m     grad_scale\u001b[38;5;241m=\u001b[39mgrad_scale,\n\u001b[0;32m    357\u001b[0m     found_inf\u001b[38;5;241m=\u001b[39mfound_inf,\n\u001b[0;32m    358\u001b[0m     has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[0;32m    359\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\AUC\\anaconda3\\Lib\\site-packages\\torch\\optim\\adamw.py:419\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[0;32m    416\u001b[0m param\u001b[38;5;241m.\u001b[39mmul_(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m lr \u001b[38;5;241m*\u001b[39m weight_decay)\n\u001b[0;32m    418\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m--> 419\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mlerp_(grad, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[0;32m    420\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "losses = torch.tensor([])\n",
    "for epoch in range(num_epochs):  # number of epochs\n",
    "    model.train()\n",
    "    model.to(get_device())\n",
    "    i = 0\n",
    "    for batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "        input_ids = input_ids.to(get_device())\n",
    "        attention_mask = attention_mask.to(get_device())\n",
    "        labels = labels.to(get_device())\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs[0]\n",
    "        losses = torch.cat((losses, loss.view(1)))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"iteration {i+1}, Loss: {loss.item()}\")\n",
    "        i += 1\n",
    "    print(f\"Epoch {epoch+1}, Loss: {losses.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_meter(text, model, tokenizer):\n",
    "    model.eval()\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    inputs = {key: val.to(model.device) for key, val in inputs.items()}\n",
    "\n",
    "    # Predict the meter using the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predictions = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "    # Return the predicted meter class (as integer)\n",
    "    return predictions.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "الطويل\n",
      "Predicted Meter Class: الطويل\n"
     ]
    }
   ],
   "source": [
    "# get random index\n",
    "text_example = meters.iloc[36]\n",
    "print(text_example['البحر'])\n",
    "example_text = \"خَليلَيَّ لا تَستَعجِلا أَن تَزَوَّدا\"\n",
    "predicted_meter = predict_meter(text_example['الشطر'], model, tokenizer)\n",
    "labelling = {v: k for k, v in label_dict.items()}\n",
    "print(f\"Predicted Meter Class: {labelling[predicted_meter]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[200], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming 'labels' is a list or array of your labels\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m label_counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(labels, return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(label_counts[\u001b[38;5;241m0\u001b[39m], label_counts[\u001b[38;5;241m1\u001b[39m])))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
